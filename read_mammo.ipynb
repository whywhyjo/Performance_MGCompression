{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "from Classifier import MGClassifier\n",
    "import utils\n",
    "import torch\n",
    "import time\n",
    "\n",
    "## row min/max , col min/max\n",
    "## 2294 4096 1914 3328\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "row_min =9999\n",
    "row_max =0\n",
    "col_min =9999\n",
    "col_max =0\n",
    "for _, path in pt_id_lossless.items():\n",
    "    tmp = pydicom.read_file(path+'/RMLO.dcm')\n",
    "    if row_min >tmp.Rows:\n",
    "        row_min = tmp.Rows\n",
    "    if row_max <tmp.Rows:\n",
    "        row_max = tmp.Rows\n",
    "    if col_min >tmp.Columns:\n",
    "        col_min = tmp.Columns\n",
    "    if col_max <tmp.Columns:\n",
    "        col_max = tmp.Columns\n",
    "\n",
    "print(row_min, row_max,col_min,col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complementary\n"
     ]
    }
   ],
   "source": [
    "## read files and their infos\n",
    "# searching dcm files \n",
    "pt_id_lossy = {}\n",
    "path_data = '/share_folder/data/breast_hu/lossy/'\n",
    "for dir_name,_,files in os.walk(path_data):\n",
    "    try:  \n",
    "        dir_name.split('/')[6]\n",
    "    except: pass\n",
    "    else:\n",
    "        pt_str = dir_name.split('/')[6]\n",
    "        #pt_status = dir_name.split('/')[5]\n",
    "        pt_id_lossy[pt_str] = dir_name\n",
    "\n",
    "\n",
    "pt_id_lossless = {}\n",
    "path_data = '/share_folder/data/breast_hu/lossless/'\n",
    "for dir_name,_,files in os.walk(path_data):\n",
    "    try:  \n",
    "        dir_name.split('/')[6]\n",
    "    except: pass\n",
    "    else:\n",
    "        pt_str = dir_name.split('/')[6]\n",
    "       # pt_status = dir_name.split('/')[5]\n",
    "        pt_id_lossless[pt_str] = dir_name\n",
    "\n",
    "## check files \n",
    "if set(pt_id_lossless.keys()).difference(set( pt_id_lossy.keys())) == set():\n",
    "    print('Complementary')\n",
    "\n",
    "pt_id = list(pt_id_lossless.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_path = '/share_folder/data/breast_hu/lossy/'\n",
    "for key, item in pt_id_lossy.items():\n",
    "    status = item.split('/')[5] \n",
    "    save_path = new_path+status+'/'+key\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    np.save(save_path+'/RMLO.npy',pydicom.read_file(item+'/RMLO.dcm').pixel_array)\n",
    "    np.save(save_path+'/LMLO.npy',pydicom.read_file(item+'/LMLO.dcm').pixel_array)\n",
    "    np.save(save_path+'/RCC.npy',pydicom.read_file(item+'/RCC.dcm').pixel_array)\n",
    "    np.save(save_path+'/LCC.npy',pydicom.read_file(item+'/LCC.dcm').pixel_array)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_path = '/share_folder/data/breast_hu/lossless/'\n",
    "for key, item in pt_id_lossless.items():\n",
    "    status = item.split('/')[5] \n",
    "    save_path = new_path+status+'/'+key\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    np.save(save_path+'/RMLO.npy',pydicom.read_file(item+'/RMLO.dcm').pixel_array)\n",
    "    np.save(save_path+'/LMLO.npy',pydicom.read_file(item+'/LMLO.dcm').pixel_array)\n",
    "    np.save(save_path+'/RCC.npy',pydicom.read_file(item+'/RCC.dcm').pixel_array)\n",
    "    np.save(save_path+'/LCC.npy',pydicom.read_file(item+'/LCC.dcm').pixel_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(pt_id,test_size=0.25, random_state=42)\n",
    "batch_size =8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== \n",
      "\n",
      "Model name: MGClassifierlossy10020742_9393\n",
      "Model Info: MGClassifier(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(15, 15), stride=(3, 3), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(4, 8, kernel_size=(15, 15), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(8, 16, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (net): ResNet(\n",
      "    (conv1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=10240, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=3, bias=True)\n",
      "      (3): Softmax(dim=1)\n",
      "    )\n",
      "    (linear): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "================================================== \n",
      "\n",
      "Model name: MGClassifierlossless10020742_8290\n",
      "Model Info: MGClassifier(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(15, 15), stride=(3, 3), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(4, 8, kernel_size=(15, 15), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(8, 16, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (net): ResNet(\n",
      "    (conv1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=10240, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=3, bias=True)\n",
      "      (3): Softmax(dim=1)\n",
      "    )\n",
      "    (linear): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_lossy = utils.DeepModel(MGClassifier(), num_classes =3, criterion = torch.nn.CrossEntropyLoss() ,note='lossy')\n",
    "model_lossless = utils.DeepModel(MGClassifier(), num_classes =3, criterion = torch.nn.CrossEntropyLoss() ,note='lossless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batch =  0\n",
      "read time: 102.202 sec\n",
      "Training data shape: (8, 4, 1, 4096, 3328) (8,)\n",
      "~~~~~~~~~~~~~~~~~~~~ Training ~~~~~~~~~~~~~~~~~~~~\n",
      "2 GPUs used!\n",
      "0th loss: 1.0807 | Precision: 0.0000 | Recall: 0.0000\n",
      "0th loss:1.08072\n",
      "*** Complete! Training time: 4.940 sec ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(train[:8]),batch_size):\n",
    "    batch_ids = train[i:i+batch_size]\n",
    "    print('num_batch = ',i)\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    t = time.process_time() \n",
    "    for j in range (batch_size):\n",
    "        pt_mammo = []\n",
    "        path = pt_id_lossy[batch_ids[j]]\n",
    "        if path.split('/')[5] =='normal':\n",
    "            y_batch.append(0)\n",
    "        elif path.split('/')[5] =='benign':\n",
    "            y_batch.append(1)\n",
    "        else:\n",
    "            y_batch.append(2)\n",
    "        tmp = np.load(path+'/RMLO.npy')#pydicom.read_file(path+'/RMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp )\n",
    "        \n",
    "        tmp = np.load(path+'/LMLO.npy') #pydicom.read_file(path+'/LMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/RCC.npy') #pydicom.read_file(path+'/RCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/LCC.npy') #pydicom.read_file(path+'/LCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp) \n",
    "        \n",
    "        X_batch.append(np.array(pt_mammo))\n",
    "    print('read time:', '{:.3f}'.format(time.process_time() - t),'sec')\n",
    "    X_batch = np.array(X_batch)    \n",
    "    y_batch = np.array(y_batch)  \n",
    "    model_lossy.training(X_batch,y_batch,batch_size = batch_size,epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batch =  0\n",
      "read time: 77.956 sec\n",
      "Training data shape: (8, 4, 1, 4096, 3328) (8,)\n",
      "~~~~~~~~~~~~~~~~~~~~ Training ~~~~~~~~~~~~~~~~~~~~\n",
      "2 GPUs used!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/root/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/root/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 146, in forward\n    \"them on device: {}\".format(self.src_device_obj, t.device))\nRuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-45f692e7c7fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodel_lossy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/share_folder/playground/ncc_jyy/run_code/lossy/utils.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, X_train, y_train, batch_size, epoch, stopping_th, save)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_variables_GPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CrossEntropyLoss()'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_variables_GPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/root/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/root/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 146, in forward\n    \"them on device: {}\".format(self.src_device_obj, t.device))\nRuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(train[:8]),batch_size):\n",
    "    batch_ids = train[i:i+batch_size]\n",
    "    print('num_batch = ',i)\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    t = time.process_time() \n",
    "    for j in range (batch_size):\n",
    "        pt_mammo = []\n",
    "        path = pt_id_lossless[batch_ids[j]]\n",
    "        if path.split('/')[5] =='normal':\n",
    "            y_batch.append(0)\n",
    "        elif path.split('/')[5] =='benign':\n",
    "            y_batch.append(1)\n",
    "        else:\n",
    "            y_batch.append(2)\n",
    "        tmp = np.load(path+'/RMLO.npy')#pydicom.read_file(path+'/RMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp )\n",
    "        \n",
    "        tmp = np.load(path+'/LMLO.npy') #pydicom.read_file(path+'/LMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/RCC.npy') #pydicom.read_file(path+'/RCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/LCC.npy') #pydicom.read_file(path+'/LCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp) \n",
    "        \n",
    "        X_batch.append(np.array(pt_mammo))\n",
    "    print('read time:', '{:.3f}'.format(time.process_time() - t),'sec')\n",
    "    X_batch = np.array(X_batch)    \n",
    "    y_batch = np.array(y_batch)  \n",
    "    model_lossy.training(X_batch,y_batch,batch_size = batch_size,epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch = []\n",
    "for i in range(0,len(test[:32]),batch_size):\n",
    "    batch_ids = test[i:i+batch_size]\n",
    "    print('num_batch = ',i)\n",
    "    X_batch = []\n",
    "    for j in range (batch_size):\n",
    "        pt_mammo = []\n",
    "        path = pt_id_lossless[batch_ids[j]]\n",
    "        if path.split('/')[5] =='normal':\n",
    "            y_batch.append(0)\n",
    "        elif path.split('/')[5] =='benign':\n",
    "            y_batch.append(1)\n",
    "        else:\n",
    "            y_batch.append(2)\n",
    "        tmp = np.load(path+'/RMLO.npy')#pydicom.read_file(path+'/RMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp )\n",
    "        \n",
    "        tmp = np.load(path+'/LMLO.npy') #pydicom.read_file(path+'/LMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/RCC.npy') #pydicom.read_file(path+'/RCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/LCC.npy') #pydicom.read_file(path+'/LCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp) \n",
    "        \n",
    "        X_batch.append(np.array(pt_mammo))\n",
    "    X_batch = np.array(X_batch)    \n",
    "    model.test(X_batch,batch_size = batch_size)\n",
    "y_batch = np.array(y_batch)  \n",
    "model_lossless.evaluation(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch = []\n",
    "for i in range(0,len(test[:32]),batch_size):\n",
    "    batch_ids = test[i:i+batch_size]\n",
    "    print('num_batch = ',i)\n",
    "    X_batch = []\n",
    "    for j in range (batch_size):\n",
    "        pt_mammo = []\n",
    "        path = pt_id_lossy[batch_ids[j]]\n",
    "        if path.split('/')[5] =='normal':\n",
    "            y_batch.append(0)\n",
    "        elif path.split('/')[5] =='benign':\n",
    "            y_batch.append(1)\n",
    "        else:\n",
    "            y_batch.append(2)\n",
    "        tmp = np.load(path+'/RMLO.npy')#pydicom.read_file(path+'/RMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp )\n",
    "        \n",
    "        tmp = np.load(path+'/LMLO.npy') #pydicom.read_file(path+'/LMLO.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/RCC.npy') #pydicom.read_file(path+'/RCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp)\n",
    "        \n",
    "        tmp = np.load(path+'/LCC.npy') #pydicom.read_file(path+'/LCC.dcm').pixel_array\n",
    "        tmp = np.pad(tmp,((0, 4096-tmp.shape[0]), (0, 3328-tmp.shape[1])),mode='constant')\n",
    "        tmp = (tmp-tmp.min()) / (tmp.max()-tmp.min())\n",
    "        tmp = tmp.reshape(1,tmp.shape[0],tmp.shape[1])\n",
    "        pt_mammo.append(tmp) \n",
    "        \n",
    "        X_batch.append(np.array(pt_mammo))\n",
    "    X_batch = np.array(X_batch)    \n",
    "    model.test(X_batch,batch_size = batch_size)\n",
    "y_batch = np.array(y_batch)  \n",
    "model_lossy.evaluation(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.performance_comparison([model])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
